# Constructing benchmark/test sets for OpenFF quantum chemistry benchmarks

Here, our key question is how to benchmark OpenFF performance on quantum chemistry data.
Specifically, we are interested in selecting (from available data) sets of molecules which contain similar chemistry to those which were fit on, and which are drug-like, to assess our performance after refitting.

We plan to construct test and benchmark sets; test sets will be potentially revisited multiple times in the leadup to a release to assess how various refits are impacting progress. A benchmark set will be utilized once, following the release, to provide a final assessment of progress.

Here, we will be drawing on available data (several QM data sets) and training sets to assist in selection of test/benchmark data.

Author: David L. Mobley (UCI)

## Draft procedure

Our initial draft procedure is as follows:

- Compute similarity of molecules in our dataset (potentially after additional filtering for drug-likeness if needed) to molecules in the training set; initially we will use OEGraphSim for this
- Retain those molecules with sufficient similarity for use in primary test/benchmark sets
- Those molecules with low similarity will be served for `stretch` test/benchmark sets which will be more challenging
- Potentially, an additional assessment of parameter usage will be applied: Molecules in the primary test/benchmark sets should only utilize parameters which are well represented in the training set.

## Detailed plans/steps:

1. Obtain training set data and potential test set data
2. Obtain parameter usage statistics for training set data
3. Compute chemical graph similarity matrix of all molecules
4. Cluster all molecules based on graph similarity using `DBSCAN`
5. Pick potential test set molecules as those which are in clusters with at least one training set molecule.
6. Save molecules which are NOT in clusters with training set molecules as potential "stretch test set" molecules
7. Check parameter usage of all potential primary test set molecules; any which use especially unusual parameters get moved from test set to stretch test set
8. Take candidate test set/stretch test set molecules and randomly partition them into test and benchmark sets (primary and stretch)


## Data availability

Some potential benchmark systems are still running on QCFractal as of this writing. Status can be assessed using info from the [QCArchive docs](https://qcarchivetutorials.readthedocs.io/en/latest/basic_examples/torsiondrive_datasets.html#Exploring-the-Dataset), specifically see the `status` functionality.

## Manifest

- `openff_unconstrained-1.0.0-RC1.offxml` from https://github.com/openforcefield/openforcefields; OpenFF 1.0 release candidate 1.
- `divide_sets.ipynb`, initial Jupyter notebook to attempt dividing up into primary and stretch sets.
- `target_smiles.txt`, SMILES strings of unique molecules used in OpenFF 1.0 RC1 fitting (from Yudong Qiu, Sept. 18, 2019)
- `cluster_pdfs`, if present: Auto-generated by `divide_sets.ipynb`; gives view of current clusters.
- `test_set_pdfs`, if present: Auto-generated by `divide_sets.ipynb`; gives view of proposed test/benchmark sets (primary and stretch) 
